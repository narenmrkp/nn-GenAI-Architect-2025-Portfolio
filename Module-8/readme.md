ğŸ“˜ Module-8: Explainable AI â€“ SHAP & LIME
ğŸ” Build trust in ML predictions with visual explanations
ğŸ¯ Focus: Diabetes prediction using SHAP & LIME interpretability tools

ğŸ“Œ Overview
In this project, we build a Random Forest classifier to predict diabetes and apply SHAP and LIME to interpret how the model makes decisions â€” both globally and locally.

ğŸ“Š Dataset
Name: Pima Indians Diabetes Dataset
Features: 8 medical indicators (e.g., Glucose, BMI, Age)
Target: Outcome (1 = Diabetes, 0 = No Diabetes)
Source: Kaggle / Plotly dataset

ğŸ”§ Tools & Libraries Used
| Tool             | Purpose                        |
| ---------------- | ------------------------------ |
| `RandomForest`   | ML Model                       |
| `SHAP`           | Global & local explanations    |
| `LIME`           | Instance-specific explanations |
| `Matplotlib`     | Visualization                  |
| `Pandas`/`NumPy` | Data handling                  |

ğŸš€ Steps Covered
Load and explore the dataset
Train a Random Forest classifier
Generate accuracy metrics
Use SHAP for:
  Global feature importance (summary plot)
  Local explanation (force plot)
Use LIME for:
  Explaining individual predictions

ğŸ“ˆ Model Performance
| Metric    | Value (may vary) |
| --------- | ---------------- |
| Accuracy  | âœ… \~76%          |
| Precision | âœ… Balanced       |
| Recall    | âœ… Balanced       |

ğŸ”· SHAP Force Plot (Local)
Explains how each feature pushed prediction for a single row
<img src="https://shap.readthedocs.io/en/latest/_images/force_plot.png" width="700"/>

ğŸŸ¢ LIME Explanation
Tabular breakdown of a predictionâ€™s local reasoning
<img src="https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/lime_tabular.png" width="500"/>

ğŸ’¾ Files in This Module
Module-8-ExplainableAI/
â”œâ”€â”€ shap_lime_diabetes.ipynb      # Full working notebook
â”œâ”€â”€ shap_values_class1.csv        # SHAP values (class 1 only)
â”œâ”€â”€ rf_diabetes_model.pkl         # Trained model
â”œâ”€â”€ README.md                     # This file (copy-paste below)

ğŸ§  What Youâ€™ll Learn
âœ… How SHAP explains models at global + local levels
âœ… How LIME generates interpretable approximations for specific predictions
âœ… Why interpretability is essential in real-world ML systems

ğŸ”œ Whatâ€™s Next?
Continue to:

ğŸ‘‰ Module-9: ML Deployment with FastAPI + Docker
Deploy this model as a REST API and serve real-time predictions!

ğŸ™Œ Credits
Created by: Nandyala Narendra
Guided via: ML + XAI Series (Modules 1â€“10)
License: MIT
