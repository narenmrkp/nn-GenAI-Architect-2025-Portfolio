# ğŸ§  ML Module-6: Dimensionality Reduction & Feature Selection

> Reduce high-dimensional data without losing predictive power.
---

## ğŸ“Œ Techniques Covered
- ğŸ”¹ Correlation Matrix + Chi2
- ğŸ”¸ RFE (Wrapper) & Lasso (Embedded)
- ğŸ“‰ PCA (Principal Component Analysis)
- ğŸ¨ t-SNE / UMAP (Optional advanced viz)
---

## ğŸ“ˆ Scree Plot â€“ PCA Variance Explained
Uploaded
---

## ğŸ’» Final Project: Breast Cancer Classifier with PCA

| Model | Input Features | Accuracy |
|-------|----------------|----------|
| Logistic Regression | All Features | 96.49% |
| Logistic + PCA (10D) | 10 Components | 97.36% âœ… |

---

## ğŸ“‚ Outputs
- âœ”ï¸ Top 10 Chi2 Features
- âœ”ï¸ Top 10 RFE Features
- âœ”ï¸ PCA Scree plot
- âœ”ï¸ Confusion Matrix
- âœ”ï¸ Classification Report

---
## ğŸ“‹ Interview Questions

1. What is the curse of dimensionality?
2. Difference between PCA and Feature Selection?
3. When to use Embedded methods vs Filter?
4. Whatâ€™s the difference between t-SNE and PCA?
---

## ğŸ“Š Sample Chart
Uploaded

> ğŸ“This project improves model performance and reduces overfitting by using PCA & RFE techniques.
-------------------------------------------------------------------------------------------------------------
Advanced DR Techniques:
## ğŸ§  Advanced Dimensionality Reduction

| Technique     | Type       | Use Case                    | Notes                        |
|---------------|------------|-----------------------------|------------------------------|
| Autoencoder   | Deep NN    | Feature compression         | Learns non-linear embeddings |
| t-SNE         | Non-linear | Cluster visualization (2D) | Slow, not for production use |
| UMAP          | Non-linear | Visualization + clustering | Faster, preserves structure  |
---

### ğŸ” Autoencoder Output
- Input shape: (569, 30)
- Compressed to: (569, 5)
- MSE loss converged âœ…
---

### ğŸ¨ Visualizations
- âœ… t-SNE shows clear class separation
- âœ… UMAP gives better global + local grouping
----------------------------------------------------------------------------------------------------
Summary:
| Technique    | Purpose                  | Best For                 |
| ------------ | ------------------------ | ------------------------ |
| PCA          | Linear DR                | Model training           |
| RFE, Lasso   | Feature Selection        | Model optimization       |
| Autoencoder  | Deep learning DR         | NLP, images, time-series |
| t-SNE / UMAP | Non-linear visualization | EDA, Clustering          |

 1. Autoencoders (Neural Network based DR)
ğŸ“˜ What is it?
Autoencoders learn a compressed representation (bottleneck) of input data using neural networks.
  ğŸ¯ Encoder compresses â†’ Decoder reconstructs
  The "bottleneck" is your reduced dimension!
